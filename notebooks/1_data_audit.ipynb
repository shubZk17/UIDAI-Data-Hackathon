{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cedcb31",
   "metadata": {},
   "source": [
    "Schema validation of the dataset,\n",
    "Concatinated the base layer of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2314ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62663c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'biometric': WindowsPath('c:/Users/BIT/OneDrive/Desktop/UIDAI Hackathon/data/aadhar biometric data'),\n",
       "  'demographic': WindowsPath('c:/Users/BIT/OneDrive/Desktop/UIDAI Hackathon/data/aadhar demographic data'),\n",
       "  'enrollment': WindowsPath('c:/Users/BIT/OneDrive/Desktop/UIDAI Hackathon/data/aadhar enrolment data')},\n",
       " WindowsPath('c:/Users/BIT/OneDrive/Desktop/UIDAI Hackathon/data/intermediate'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Project root (adjust if needed)\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\"\n",
    "\n",
    "RAW_PATHS = {\n",
    "    \"biometric\": DATA_ROOT / \"aadhar biometric data\",\n",
    "    \"demographic\": DATA_ROOT / \"aadhar demographic data\",\n",
    "    \"enrollment\": DATA_ROOT / \"aadhar enrolment data\"\n",
    "}\n",
    "\n",
    "INTERMEDIATE_PATH = DATA_ROOT / \"intermediate\"\n",
    "INTERMEDIATE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_PATHS, INTERMEDIATE_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "575b39b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csvs_from_folder(folder_path: Path) -> List[pd.DataFrame]:\n",
    "    csv_files = sorted(folder_path.glob(\"*.csv\"))\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {folder_path}\")\n",
    "    \n",
    "    dfs = []\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df[\"source_file\"] = file.name  # traceability\n",
    "        dfs.append(df)\n",
    "    \n",
    "    print(f\"Loaded {len(dfs)} files from {folder_path.name}\")\n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f35464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_schema_consistency(dfs: List[pd.DataFrame]) -> Tuple[bool, List[set]]:\n",
    "    schemas = [set(df.columns) for df in dfs]\n",
    "    base_schema = schemas[0]\n",
    "    \n",
    "    mismatches = [schema for schema in schemas if schema != base_schema]\n",
    "    \n",
    "    if mismatches:\n",
    "        print(\"❌ Schema mismatch detected\")\n",
    "        return False, schemas\n",
    "    \n",
    "    print(\"✅ All schemas match\")\n",
    "    return True, schemas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12105a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_concatenate(dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    return pd.concat(dfs, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdf3d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_name: str, folder_path: Path) -> pd.DataFrame:\n",
    "    print(f\"\\n--- Processing {dataset_name.upper()} DATA ---\")\n",
    "    \n",
    "    dfs = load_csvs_from_folder(folder_path)\n",
    "    is_consistent, schemas = check_schema_consistency(dfs)\n",
    "    \n",
    "    if not is_consistent:\n",
    "        raise ValueError(f\"Schema mismatch in {dataset_name} dataset\")\n",
    "    \n",
    "    df_final = safe_concatenate(dfs)\n",
    "    \n",
    "    print(f\"Final shape: {df_final.shape}\")\n",
    "    print(\"Missing values (%):\")\n",
    "    display((df_final.isna().mean() * 100).sort_values(ascending=False).head(10))\n",
    "    \n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20028ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing BIOMETRIC DATA ---\n",
      "Loaded 4 files from aadhar biometric data\n",
      "✅ All schemas match\n",
      "Final shape: (1861108, 7)\n",
      "Missing values (%):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date            0.0\n",
       "state           0.0\n",
       "district        0.0\n",
       "pincode         0.0\n",
       "bio_age_5_17    0.0\n",
       "bio_age_17_     0.0\n",
       "source_file     0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing DEMOGRAPHIC DATA ---\n",
      "Loaded 4 files from aadhar demographic data\n",
      "✅ All schemas match\n",
      "Final shape: (1571700, 7)\n",
      "Missing values (%):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date             0.0\n",
       "state            0.0\n",
       "district         0.0\n",
       "pincode          0.0\n",
       "demo_age_5_17    0.0\n",
       "demo_age_17_     0.0\n",
       "source_file      0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing ENROLLMENT DATA ---\n",
      "Loaded 3 files from aadhar enrolment data\n",
      "✅ All schemas match\n",
      "Final shape: (1006029, 8)\n",
      "Missing values (%):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date              0.0\n",
       "state             0.0\n",
       "district          0.0\n",
       "pincode           0.0\n",
       "age_0_5           0.0\n",
       "age_5_17          0.0\n",
       "age_18_greater    0.0\n",
       "source_file       0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "biometric_df = process_dataset(\"biometric\", RAW_PATHS[\"biometric\"])\n",
    "demographic_df = process_dataset(\"demographic\", RAW_PATHS[\"demographic\"])\n",
    "enrollment_df = process_dataset(\"enrollment\", RAW_PATHS[\"enrollment\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fabb4965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('c:/Users/BIT/OneDrive/Desktop/UIDAI Hackathon/data/intermediate/biometric_base.parquet'),\n",
       " WindowsPath('c:/Users/BIT/OneDrive/Desktop/UIDAI Hackathon/data/intermediate/demographic_base.parquet'),\n",
       " WindowsPath('c:/Users/BIT/OneDrive/Desktop/UIDAI Hackathon/data/intermediate/enrollment_base.parquet'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biometric_path = INTERMEDIATE_PATH / \"biometric_base.parquet\"\n",
    "demographic_path = INTERMEDIATE_PATH / \"demographic_base.parquet\"\n",
    "enrollment_path = INTERMEDIATE_PATH / \"enrollment_base.parquet\"\n",
    "\n",
    "biometric_df.to_parquet(biometric_path, index=False)\n",
    "demographic_df.to_parquet(demographic_path, index=False)\n",
    "enrollment_df.to_parquet(enrollment_path, index=False)\n",
    "\n",
    "biometric_path, demographic_path, enrollment_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b72d601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>rows</th>\n",
       "      <th>columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biometric</td>\n",
       "      <td>1861108</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>demographic</td>\n",
       "      <td>1571700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enrollment</td>\n",
       "      <td>1006029</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset     rows  columns\n",
       "0    biometric  1861108        7\n",
       "1  demographic  1571700        7\n",
       "2   enrollment  1006029        8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = pd.DataFrame({\n",
    "    \"dataset\": [\"biometric\", \"demographic\", \"enrollment\"],\n",
    "    \"rows\": [len(biometric_df), len(demographic_df), len(enrollment_df)],\n",
    "    \"columns\": [\n",
    "        biometric_df.shape[1],\n",
    "        demographic_df.shape[1],\n",
    "        enrollment_df.shape[1]\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c55d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
